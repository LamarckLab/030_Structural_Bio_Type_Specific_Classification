{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65330c80-25f0-4ca0-aeb9-56ef913a7679",
   "metadata": {},
   "source": [
    "## 1 环境与数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc26a6-6685-4279-b282-8c8b8ede9da8",
   "metadata": {},
   "source": [
    "### 1.1 安装和导入常用库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562d138-41f6-4316-91f6-7be8efdb1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import os\n",
    "\n",
    "# 查看当前PyTorch是否可用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ed910-2168-4784-b43c-472d00d5ae5f",
   "metadata": {},
   "source": [
    "### 1.2 读取csv数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42984b2e-ea5e-47a6-9315-3364510b83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Lamarck\\Desktop\\CDRs.csv')\n",
    "print(df.head()) # 查看前5行\n",
    "print(df.shape)  # 查看行列数\n",
    "\n",
    "print(df['type'].value_counts())  # 查看每个亚型的样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c18d7-e964-4ea7-949c-01d97036b103",
   "metadata": {},
   "source": [
    "## 2 数据探索与预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173839cb-40db-4d8c-8a7c-c14408b3bf27",
   "metadata": {},
   "source": [
    "### 2.1 检查缺失值与重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e955489-3035-4e90-86fb-fb9dfcc8a641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"缺失值统计:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"重复行数量:\", df.duplicated().sum())\n",
    "\n",
    "print(\"各亚型分布:\")\n",
    "print(df['type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03374d0-9816-4ec9-a34f-cc5ed41da881",
   "metadata": {},
   "source": [
    "### 2.2 编码类别标签\n",
    "#### 对hpv抗体的亚型类别进行标签编码(将类别型数据转换为数值型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bba127-0351-4cc8-bd96-d2449d5568dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['type'])\n",
    "num_classes = len(le.classes_)  # 这里应为9\n",
    "print(\"标签对应关系:\", dict(zip(le.classes_, range(num_classes))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95514c76-be0d-4f65-a878-bf691862ae0f",
   "metadata": {},
   "source": [
    "### 2.3 查看序列长度分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c3fe4-8d49-4718-a47b-0e440ad6e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdrs = ['HCDR1', 'HCDR2', 'HCDR3', 'LCDR1', 'LCDR2', 'LCDR3']\n",
    "for c in cdrs:\n",
    "    lengths = df[c].apply(len)\n",
    "    print(f\"{c} 平均长度: {lengths.mean():.2f}, 最大长度: {lengths.max()}, 最小长度: {lengths.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba06190-5db4-439b-91a4-8e46b5e505cd",
   "metadata": {},
   "source": [
    "## 3 数据划分与交叉验证\n",
    "#### 训练集60% 验证集20% 测试集20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6936758-9583-475d-af5e-09aa130b5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, \n",
    "                                     stratify=df['label'], \n",
    "                                     random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, \n",
    "                                    stratify=train_df['label'], \n",
    "                                    random_state=42)\n",
    "\n",
    "print(\"Train size:\", len(train_df), \"Val size:\", len(val_df), \"Test size:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc4b53-da29-4355-b0ac-d212dc2f759e",
   "metadata": {},
   "source": [
    "## 4 序列编码与特征表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c83774-871c-42a5-9b04-08ec9c355380",
   "metadata": {},
   "source": [
    "### 4.1 构建氨基酸字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb4ee1-6795-4840-aa8e-7101307b4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")  # 常见20种\n",
    "PAD_TOKEN = \"<PAD>\" # 用于填充短序列, 确保所有氨基酸序列长度相同\n",
    "UNK_TOKEN = \"<UNK>\" # 标记未知字符, 如果遇到非标准氨基酸，直接映射到这个字符\n",
    "vocab = [PAD_TOKEN, UNK_TOKEN] + amino_acids # 将 <PAD> 和 <UNK> 添加到氨基酸列表的前面\n",
    "vocab2idx = {v: i for i, v in enumerate(vocab)} # 氨基酸的索引字典\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "print(\"vocab2idx:\", vocab2idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a05e5f-a320-474e-8253-ff3997905ccc",
   "metadata": {},
   "source": [
    "### 4.2 将氨基酸序列转换为索引并填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c880e4e-68a8-4ec9-b0cb-6a2b211cf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 35 # 短于35的需要填充，长于35的需要截断\n",
    "\n",
    "def seq2indices(seq, vocab2idx, max_len=35):\n",
    "    indices = []\n",
    "    for char in seq:\n",
    "        if char in vocab2idx:\n",
    "            indices.append(vocab2idx[char]) # 直接转换\n",
    "        else:\n",
    "            indices.append(vocab2idx[UNK_TOKEN]) # 遇到未知字符，用<UNK>代替\n",
    "    # 填充或截断\n",
    "    if len(indices) < max_len:\n",
    "        indices += [vocab2idx[PAD_TOKEN]] * (max_len - len(indices)) # 填充\n",
    "    else:\n",
    "        indices = indices[:max_len] # 截断\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52336034-f5b2-45d5-855d-d12019174755",
   "metadata": {},
   "source": [
    "### 4.3 将每行样本(6个CDR)转换为数值向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ed3e3-c30e-4f6f-a8ae-733e6baffba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, vocab2idx, max_len=35):\n",
    "    cdr_cols = ['HCDR1','HCDR2','HCDR3','LCDR1','LCDR2','LCDR3']\n",
    "    \n",
    "    X_data = [] # X_data 用于存储转换后的 CDR 序列索引（数值化的氨基酸）\n",
    "    y_data = df['label'].values # y_data 直接获取 df['label']（HPV 亚型标签）\n",
    "\n",
    "    # 遍历DataFrame的每一行\n",
    "    for _, row in df.iterrows():\n",
    "        cdr_indices_list = []\n",
    "        for col in cdr_cols:\n",
    "            seq = row[col]\n",
    "            idx_seq = seq2indices(seq, vocab2idx, max_len)\n",
    "            cdr_indices_list.append(idx_seq)\n",
    "        # 得到 shape: [6, max_len]\n",
    "        X_data.append(cdr_indices_list)\n",
    "    \n",
    "    X_data = np.array(X_data)  # => [N, 6, max_len]\n",
    "    return X_data, y_data\n",
    "\n",
    "X_train, y_train = process_dataframe(train_df, vocab2idx, MAX_LEN)\n",
    "X_val, y_val = process_dataframe(val_df, vocab2idx, MAX_LEN)\n",
    "X_test, y_test = process_dataframe(test_df, vocab2idx, MAX_LEN)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64478d5-3641-49fb-8639-668650cd79f4",
   "metadata": {},
   "source": [
    "### 4.4 构建 PyTorch Dataset 和 DataLoader\n",
    "#### 将 CDR 序列数据包装成 PyTorch Dataset 和 DataLoader，以便在神经网络训练时高效加载小批量数据（batch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d4c45-1c55-40f5-b80c-05207ef73fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch提供的一个抽象类用于定义数据集的结构\n",
    "class CDRDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        x_item = torch.LongTensor(self.X[idx])  # shape: [6, max_len]\n",
    "        y_item = torch.LongTensor([self.y[idx]])  # shape: [1], 也可返回int\n",
    "        return x_item, y_item\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# 创建 Dataset\n",
    "train_dataset = CDRDataset(X_train, y_train)\n",
    "val_dataset   = CDRDataset(X_val, y_val)\n",
    "test_dataset  = CDRDataset(X_test, y_test)\n",
    "\n",
    "# 使用 DataLoader 加载数据\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b46040-2033-4e06-8146-be44f229a7ff",
   "metadata": {},
   "source": [
    "## 5 搭建模型\n",
    "#### 用一个共享的 Embedding + 1D 卷积 + 池化来为每条 CDR 提取特征，然后拼接 6 路结果再分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfed831-1734-4380-983e-b01f0bf2a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDRClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=32, hidden_dim=64, num_classes=9):\n",
    "        super(CDRClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.conv = nn.Conv1d(in_channels=embed_dim, out_channels=hidden_dim, \n",
    "                              kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 6, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: [batch_size, 6, max_len]\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        cdr_features = []\n",
    "        \n",
    "        for i in range(6):\n",
    "            seq_i = x[:, i, :]   # [batch_size, max_len]\n",
    "            emb_i = self.embedding(seq_i)  # [batch_size, max_len, embed_dim]\n",
    "            emb_i = emb_i.permute(0, 2, 1) # => [batch_size, embed_dim, max_len]\n",
    "            \n",
    "            conv_out = self.conv(emb_i)    # => [batch_size, hidden_dim, max_len]\n",
    "            conv_out = torch.relu(conv_out)\n",
    "            pooled = self.pool(conv_out)   # => [batch_size, hidden_dim, 1]\n",
    "            pooled = pooled.squeeze(-1)     # => [batch_size, hidden_dim]\n",
    "            \n",
    "            cdr_features.append(pooled)\n",
    "        \n",
    "        # 拼接6个CDR的特征 => [batch_size, hidden_dim*6]\n",
    "        concat_feats = torch.cat(cdr_features, dim=1)\n",
    "        out = self.fc(concat_feats)\n",
    "        return out\n",
    "\n",
    "model = CDRClassifier(vocab_size=vocab_size, embed_dim=32, hidden_dim=64, \n",
    "                      num_classes=num_classes).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f172517-4005-426b-9a2b-4d6e7b5964fc",
   "metadata": {},
   "source": [
    "## 6 训练与验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55353939-3884-42e5-82d6-7505954fdbad",
   "metadata": {},
   "source": [
    "### 6.1 定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd147026-6eea-4f36-a1b7-11239ea0dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec427d9-45ad-482a-8993-58fbce02516c",
   "metadata": {},
   "source": [
    "### 6.2 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97526e9d-4f48-44b6-90ae-940e5feb6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)      # [batch_size, 6, max_len]\n",
    "        y_batch = y_batch.squeeze(1).to(device)  # [batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)         # [batch_size, num_classes]\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    # 训练集平均损失\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    \n",
    "    # 验证集评估\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val_ in val_loader:\n",
    "            X_val = X_val.to(device)\n",
    "            y_val_ = y_val_.squeeze(1).to(device)\n",
    "            \n",
    "            val_out = model(X_val)\n",
    "            val_loss = criterion(val_out, y_val_)\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            preds = torch.argmax(val_out, dim=1).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(y_val_.cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_acc:.4f} | \"\n",
    "          f\"Val F1: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342f0de-2964-49b9-a4fa-c8138515d1c4",
   "metadata": {},
   "source": [
    "## 7 在测试集上做最终评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263c6da-ec35-4ae8-80d0-327bf930819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "almost_correct_count = 0  # 计数器\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch in test_loader:\n",
    "        X_test_batch = X_test_batch.to(device)\n",
    "        y_test_batch = y_test_batch.squeeze(1).to(device)\n",
    "\n",
    "        # 前向计算\n",
    "        test_out = model(X_test_batch)        # [batch_size, num_classes]\n",
    "        preds = torch.argmax(test_out, dim=1) # [batch_size]\n",
    "\n",
    "        # ------ 计算Top-3 ------\n",
    "        # 返回 top3 的分数 (values) 和 索引 (indices)\n",
    "        _, top3_indices = torch.topk(test_out, k=3, dim=1)  # [batch_size, 3]\n",
    "\n",
    "        # 转到CPU上便于操作\n",
    "        top3_indices = top3_indices.cpu().numpy()\n",
    "        y_true_cpu = y_test_batch.cpu().numpy()\n",
    "        total_samples += len(y_true_cpu)\n",
    "\n",
    "        # 统计Almost正确数\n",
    "        for i, label_true in enumerate(y_true_cpu):\n",
    "            # top3_indices[i] 是该样本top-3预测类别, 形如 [2, 5, 1]\n",
    "            if label_true in top3_indices[i]:\n",
    "                almost_correct_count += 1\n",
    "        # ------ 计算Top-3结束 ------\n",
    "\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(y_true_cpu)\n",
    "\n",
    "# 1. 计算Top-1 Accuracy\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "# 2. 计算Almost Accuracy = (Top-3 内有正确标签) / (总数)\n",
    "almost_accuracy = almost_correct_count / total_samples\n",
    "\n",
    "print(f\"Test Accuracy (Top-1): {test_acc:.4f}\")\n",
    "print(f\"Test Almost Accuracy (Top-3): {almost_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad9eb54-93d9-4ca6-b4d1-8190501e802a",
   "metadata": {},
   "source": [
    "## 8 新样本预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab890c8b-44d5-4a57-8bb5-345c5163fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hpv_type(model, cdr_list, vocab2idx, max_len=25):\n",
    "    \"\"\"\n",
    "    cdr_list: [HCDR1, HCDR2, HCDR3, LCDR1, LCDR2, LCDR3] (6条序列)\n",
    "    返回: (prob_array, predicted_label_str)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 将6条CDR转为索引 [6, max_len]\n",
    "    input_list = []\n",
    "    for seq in cdr_list:\n",
    "        idx_seq = seq2indices(seq, vocab2idx, max_len)\n",
    "        input_list.append(idx_seq)\n",
    "    \n",
    "    X = torch.LongTensor([input_list]).to(device)  # [1, 6, max_len]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(X)  # [1, 9]\n",
    "        probs = nn.functional.softmax(logits, dim=1).cpu().numpy().squeeze()  # [9,]\n",
    "        pred_idx = np.argmax(probs)\n",
    "    \n",
    "    # 映射回真实亚型\n",
    "    pred_label = le.inverse_transform([pred_idx])[0]\n",
    "    return probs, pred_label\n",
    "\n",
    "# 示例调用\n",
    "example_cdrs = [\n",
    "    \"GFTFSSYW\",  # HCDR1 \n",
    "    \"INSDGSST\",   # HCDR2\n",
    "    \"ARSLQLWPSSDYMDV\", # HCDR3\n",
    "    \"QGISDS\",    # LCDR1\n",
    "    \"VAS\",    # LCDR2\n",
    "    \"QQINSYPPA\"   # LCDR3\n",
    "]\n",
    "prob_array, pred_type = predict_hpv_type(model, example_cdrs, vocab2idx, MAX_LEN)\n",
    "print(\"预测概率分布:\", prob_array)\n",
    "print(\"最终预测亚型:\", pred_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
